{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "arcface.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gO9jDmYkXnL"
      },
      "source": [
        "# ARCFace\n",
        "\n",
        "\n",
        "This is a simply guide that helped me to understand how arcface (https://arxiv.org/abs/1801.07698) and sphere-face (https://arxiv.org/abs/1704.08063) works.\n",
        "\n",
        "This guide will gently moves from softmax to arcface and sphere face.\n",
        "To better visualize what's going on MNIST dataset is used and a very simple architecture is used as a backbone.\n",
        "\n",
        "Have fun!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS3B6uFskXnS",
        "outputId": "63aa1a88-8892-4a0a-ed42-7abc423e0efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "%matplotlib widget\n",
        "from functools import partial\n",
        "\n",
        "# Checking if everything is alright with the GPU\n",
        "import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "from plot import plot_scatter\n",
        "\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dbac06f030f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib widget'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Checking if everything is alright with the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-105>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   2948\u001b[0m                 \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2950\u001b[0;31m         \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2951\u001b[0m         \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_inline_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;31m# This must be imported last in the matplotlib series, after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    219\u001b[0m         else \"matplotlib.backends.backend_{}\".format(newbackend.lower()))\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mbackend_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     Backend = type(\n\u001b[1;32m    223\u001b[0m         \"Backend\", (matplotlib.backends._Backend,), vars(backend_mod))\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipympl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFw04pWlkXnV"
      },
      "source": [
        "# Simple architecture used in our experiments\n",
        "\n",
        "def backbone(inputs, include_top=False, n_classes=10, training=None):\n",
        "    tf.random.set_seed(0)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\", name=\"conv1\")(inputs)\n",
        "    x = tf.keras.layers.MaxPool2D((2,2), name=\"maxp1\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(name=\"batch_norm1\")(x, training=training)\n",
        "    x = tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", name=\"conv2\")(x)\n",
        "    x = tf.keras.layers.MaxPool2D((2,2), name=\"maxp2\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(name=\"batch_norm2\")(x, training=training)\n",
        "    x = tf.keras.layers.Flatten(input_shape=x.shape[1:])(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu', name=\"fc1\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(name=\"batch_norm3\")(x, training=training)\n",
        "    x = tf.keras.layers.Dense(20, activation=None, name=\"embeddings\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(name=\"batch_norm4\")(x, training=training)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x, training=training)\n",
        "    if include_top:\n",
        "        x = tf.keras.layers.Dense(n_classes, name=\"hot\", activation=None)(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb0kTeMfkXnW"
      },
      "source": [
        "# From Softmax cross entropy to ArcFace\n",
        "\n",
        "One of the work horses of Machine Learning is the Softmax + Cross Entropy loss.\n",
        "The softmax is defined as:\n",
        "\n",
        "\n",
        "$$\\text{soft}(x_i) = \\frac{ \\text{exp}(Wx_i + b) }{\\sum_{j=1}^n \\text{exp}(Wx_j + b)}  $$\n",
        "\n",
        "and the cross entropy loss is defined as:\n",
        "\n",
        "$$L_1 = -\\frac{1}{m}\\sum\\limits_{i=1}^m y_i \\text{log}(\\text{soft}(x_i)) $$\n",
        "\n",
        "Below follow an example using Tensorflow on how to train a CNN using this loss.\n",
        "What is important in this exercise is to observe the how the embedding space is organized in this 10 class classification problem.\n",
        "\n",
        "One of the main drawbacks for the cross-entropy loss for face representation is its hability to generate a face space discriminative enough in open set scenarious.\n",
        "It's possible to have a grasp of this in the t-SNE below where the representation for each one of the 10 classes is less \"visual\" compact (within class variability) compared with other examples .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnuePyM6kXnY",
        "outputId": "599a2c6f-14b4-4c52-b8a0-763e4473eea9",
        "colab": {
          "referenced_widgets": [
            "3126709611a948aca3f0abc5c8fc7165"
          ]
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Loading MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_dataset = train_dataset.batch(64)\n",
        "\n",
        "def softmax_cross_entropy(target, output, sparse=True, n_classes=10):\n",
        "    \n",
        "    target = tf.squeeze(target)\n",
        "    \n",
        "    ## SIMPLIFIED\n",
        "    \n",
        "    logits_max = tf.math.reduce_max(output, axis=-1, keepdims=True)\n",
        "    N = logits_max.shape[0]\n",
        "    shifted_logits = output - logits_max\n",
        "    exp_shifted_logits = tf.math.exp(shifted_logits)\n",
        "    \n",
        "    if sparse:\n",
        "        y = tf.one_hot(tf.cast(target,\"int32\"), depth=n_classes)\n",
        "    else:\n",
        "        y = target\n",
        "        \n",
        "    sum_exp = tf.math.reduce_sum(exp_shifted_logits,axis=-1, keepdims=True)\n",
        "    log_sum_exp = tf.math.log(sum_exp)\n",
        "    \n",
        "    sub = shifted_logits - log_sum_exp\n",
        "    mul = tf.math.multiply(tf.math.negative(y), sub)\n",
        "    #L = tf.math.reduce_sum(mul)/N\n",
        "    L = tf.math.reduce_mean(tf.math.reduce_sum(mul, axis=-1))\n",
        "    \"\"\"    \n",
        "\n",
        "\n",
        "    ### NOT SIMPLIFIED\n",
        "    logits_max = tf.math.reduce_max(output, axis=-1, keepdims=True)\n",
        "    shifted_logits = output - logits_max    \n",
        "    exp_shifted_logits = tf.math.exp(shifted_logits)\n",
        "    sum_exp = tf.math.reduce_sum(exp_shifted_logits,axis=-1, keepdims=True)\n",
        "    softmax = exp_shifted_logits/sum_exp\n",
        "\n",
        "    if sparse:\n",
        "        y = tf.one_hot(tf.cast(target,\"int32\"), depth=n_classes)\n",
        "    else:\n",
        "        y = target\n",
        "\n",
        "    mul = tf.math.multiply(y, tf.math.log(tf.clip_by_value(softmax,1e-10,1.0)))\n",
        "    #L = -tf.reduce_sum(mul)/N    \n",
        "    L = -tf.math.reduce_mean(tf.math.reduce_sum(mul, axis=-1))\n",
        "    \"\"\"\n",
        "\n",
        "    return L\n",
        "\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "inputs = tf.keras.layers.Input([28, 28, 1], name=\"Input\")\n",
        "logits = tf.nn.l2_normalize(backbone(inputs, include_top=True),axis=1)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=softmax_cross_entropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#print(model.summary())\n",
        "\n",
        "model.fit(train_dataset, epochs=10, steps_per_epoch=None)\n",
        "\n",
        "\n",
        "predict_model = tf.keras.Model(inputs=inputs, outputs=model.get_layer(\"embeddings\").output)\n",
        "embeddings = tf.nn.l2_normalize(predict_model.predict(x_test[0:1000]),axis=1)\n",
        "plot_scatter(embeddings, y_test[0:1000])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.5502 - accuracy: 0.9366\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 1.4687 - accuracy: 0.9798\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.4612 - accuracy: 0.9798\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.4571 - accuracy: 0.9837\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 1.4563 - accuracy: 0.9833\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.4514 - accuracy: 0.9861\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.4502 - accuracy: 0.9851\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 1.4482 - accuracy: 0.9850\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 1.4465 - accuracy: 0.9880\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 21s 23ms/step - loss: 1.4470 - accuracy: 0.9877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3126709611a948aca3f0abc5c8fc7165",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeo0uFpjkXnZ"
      },
      "source": [
        "# Angular Boundaries\n",
        "\n",
        "## Modified Softmax from the paper Sphere-Face\n",
        "\n",
        "$$\\text{soft}(x_i) = \\frac{exp(||x_i||\\text{cos}(\\theta_{yi}))}{\\sum_j  exp(||x_i||\\text{cos}(\\theta_{j}))   }$$, where $cos(\\theta_i)=W_i^{\\intercal}x_i$\n",
        "\n",
        "Below follow the same example as aforementioned, but using the modified softmax.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNiooqdwkXna",
        "outputId": "be1c950f-9f54-4ba1-c6fc-3d4cda76d90d",
        "colab": {
          "referenced_widgets": [
            "382bee633fc44333a494b8c8d49486cb"
          ]
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class ModifiedSoftMaxHead(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, n_classes=10):\n",
        "        super(ModifiedSoftMaxHead, self).__init__(name =\"modified_softmax_logits\")\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        super(ModifiedSoftMaxHead, self).build(input_shape[0])\n",
        "        shape = [input_shape[-1], self.n_classes]\n",
        "        \n",
        "        self.W = self.add_variable(\"W\", shape=shape)\n",
        "        \n",
        "\n",
        "    def call(self, X, training=None):\n",
        "        \n",
        "        # normalize feature\n",
        "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
        "\n",
        "        # cos between X and W            \n",
        "        cos_yi = tf.nn.l2_normalize(X, axis=1) @ W\n",
        "                \n",
        "        logits = tf.norm(X)*cos_yi\n",
        "        \n",
        "        return logits\n",
        "    \n",
        "        \n",
        "tf.random.set_seed(0)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_dataset = train_dataset.batch(64)\n",
        "\n",
        "\n",
        "# PRE MODEL WITH CROSS ENTROPY\n",
        "n_classes = 10\n",
        "inputs = tf.keras.layers.Input([28, 28, 1], name=\"input\")\n",
        "labels = tf.keras.layers.Input([], name=\"label\")\n",
        "\n",
        "embeddings = tf.nn.l2_normalize(backbone(inputs, include_top=False),axis=1)\n",
        "logits_cross_entropy = tf.keras.layers.Dense(n_classes, name=\"hot\", activation=None)(embeddings)\n",
        "pre_model = tf.keras.Model(inputs=inputs, outputs=logits_cross_entropy)\n",
        "\n",
        "#### NOW THE MODIFIED CROSS ENTROPY\n",
        "\n",
        "logits_modsoft = ModifiedSoftMaxHead()(embeddings)\n",
        "\n",
        "modsoft_model = tf.keras.Model(inputs, outputs=logits_modsoft)\n",
        "#print(arcface_model.summary())\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "# First do cross entropy\n",
        "pre_model.compile(optimizer=optimizer,\n",
        "              loss=softmax_cross_entropy,\n",
        "              metrics=['accuracy'])\n",
        "pre_model.fit(train_dataset, epochs=1)\n",
        "\n",
        "\n",
        "# second do arcface \n",
        "modsoft_model.compile(optimizer=optimizer,\n",
        "              loss=softmax_cross_entropy,\n",
        "              metrics=['accuracy'])\n",
        "modsoft_model.fit(train_dataset, epochs=9)\n",
        "\n",
        "\n",
        "predict_model = tf.keras.Model(inputs=inputs, outputs=modsoft_model.get_layer(\"embeddings\").output)\n",
        "embeddings = tf.nn.l2_normalize(predict_model.predict(x_test[0:1000]), axis=1)\n",
        "plot_scatter(embeddings, y_test[0:1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/idiap/user/tpereira/conda/envs/bob.nightlies/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2287: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 9s 8ms/step - loss: 0.4630 - accuracy: 0.9368\n",
            "Epoch 1/9\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.1388 - accuracy: 0.9621\n",
            "Epoch 2/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0494 - accuracy: 0.9881\n",
            "Epoch 3/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0424 - accuracy: 0.9904\n",
            "Epoch 4/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0343 - accuracy: 0.9925\n",
            "Epoch 5/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0273 - accuracy: 0.9939\n",
            "Epoch 6/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0218 - accuracy: 0.9959\n",
            "Epoch 7/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0208 - accuracy: 0.9961\n",
            "Epoch 8/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0218 - accuracy: 0.9954\n",
            "Epoch 9/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0178 - accuracy: 0.9967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "382bee633fc44333a494b8c8d49486cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WZ3vm56kXna"
      },
      "source": [
        "# Sphere Face\n",
        "\n",
        "$$\\text{soft}(x_i) = \\frac{exp(||x_i||\\text{cos}(\\psi(\\theta_{yi})))}{exp(||x_i||\\text{cos}(\\psi(\\theta_{yi}))) + \\sum_{j;j\\neq yi}  exp(||x_i||\\text{cos}(\\psi(\\theta_{j})))   }$$,\n",
        "\n",
        "where, $\\psi(\\theta) = -1^k \\text{cos}(m\\theta)-2k$.\n",
        "\n",
        "In this case, $theta \\in [\\frac{k\\pi}{m} , \\frac{(k+1)\\pi}{m}]$  $k \\in [0, m-1]$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUFukSGakXnb",
        "outputId": "7e02f7ae-ef50-4ea7-f9d5-c5bfb0a4c54d",
        "colab": {
          "referenced_widgets": [
            "1a9dc5a5e09a48ccb4abcff388958699"
          ]
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# HYPERPARAMETERS\n",
        "\n",
        "M = 5.\n",
        "n_classes = 10\n",
        "\n",
        "     \n",
        "class SphereFaceLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_classes=10, m=0.5):\n",
        "        super(SphereFaceLayer, self).__init__(name =\"sphere_face_logits\")\n",
        "        self.n_classes = n_classes\n",
        "        self.m = m\n",
        "\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        super(SphereFaceLayer, self).build(input_shape[0])\n",
        "        shape = [input_shape[-1], self.n_classes]\n",
        "        \n",
        "        self.W = self.add_variable(\"W\", shape=shape)\n",
        "        self.pi = tf.constant(math.pi)\n",
        "                \n",
        "    \n",
        "    def call(self, X, training=None):\n",
        "        \n",
        "        # normalize feature\n",
        "        X = tf.nn.l2_normalize(X, axis=1)\n",
        "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
        "\n",
        "        # cos between X and W            \n",
        "        cos_yi = tf.matmul(X, W)\n",
        "\n",
        "        \n",
        "        # cos(m \\theta)\n",
        "        theta = tf.math.acos(cos_yi)    \n",
        "        cos_theta_m = tf.math.cos(self.m*theta)\n",
        "\n",
        "        # ||x||\n",
        "        x_norm = tf.norm(X, axis=-1, keepdims=True)\n",
        "        \n",
        "        # phi = -1**k * cos(m \\theta) - 2k\n",
        "        k = self.m * (theta / self.pi)        \n",
        "        phi = ((-1**k)* cos_theta_m) - 2*k\n",
        "        \n",
        "        logits = x_norm*phi\n",
        "        \n",
        "\n",
        "        # Computing the logits\n",
        "        #one_hot = tf.one_hot(tf.cast(y, tf.int32), depth=self.n_classes,\n",
        "        #                  name='one_hot_mask')\n",
        "       \n",
        "        #logits = (one_hot * phi)\n",
        "    \n",
        "        \n",
        "        return logits     \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_dataset = train_dataset.batch(64)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# PRE MODEL WITH CROSS ENTROPY\n",
        "inputs = tf.keras.layers.Input([28, 28, 1], name=\"input\")\n",
        "labels = tf.keras.layers.Input([], name=\"label\")\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "# Creating PRE MODEL\n",
        "embeddings = tf.nn.l2_normalize(backbone(inputs, include_top=False), axis=1)\n",
        "logits_cross_entropy = tf.keras.layers.Dense(n_classes, name=\"hot\", activation=None)(embeddings)\n",
        "pre_model = tf.keras.Model(inputs=inputs, outputs=logits_cross_entropy)\n",
        "\n",
        "# Arcface model\n",
        "logits_sphereface = SphereFaceLayer(m=M)(embeddings)\n",
        "sphereface_model = tf.keras.Model(inputs=inputs, outputs=logits_cross_entropy)\n",
        "#sphereface_model = AngularModel(inputs=(inputs,labels), outputs=logits_sphereface)\n",
        "\n",
        "\n",
        "#print(pre_model.summary())\n",
        "\n",
        "pre_model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "pre_model.fit(train_dataset, epochs=1)\n",
        "\n",
        "\n",
        "\n",
        "# second do arcface\n",
        "#\n",
        "sphereface_model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "sphereface_model.fit(train_dataset, epochs=9)\n",
        "\n",
        "#arcface_model.fit([x_train, y_train],y_train, epochs=20)\n",
        "\n",
        "\n",
        "\n",
        "predict_model = tf.keras.Model(inputs=inputs, outputs=sphereface_model.get_layer(\"embeddings\").output)\n",
        "embeddings = tf.nn.l2_normalize(predict_model.predict(x_test[0:1000]), axis=1)\n",
        "plot_scatter(embeddings, y_test[0:1000])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 9s 8ms/step - loss: 0.4604 - accuracy: 0.9375\n",
            "Epoch 1/9\n",
            "938/938 [==============================] - 9s 8ms/step - loss: 0.0617 - accuracy: 0.9834\n",
            "Epoch 2/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0459 - accuracy: 0.9879\n",
            "Epoch 3/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0318 - accuracy: 0.9910\n",
            "Epoch 4/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0296 - accuracy: 0.9917\n",
            "Epoch 5/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0224 - accuracy: 0.9931\n",
            "Epoch 6/9\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0186 - accuracy: 0.9946\n",
            "Epoch 7/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0154 - accuracy: 0.9948\n",
            "Epoch 8/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0157 - accuracy: 0.9949\n",
            "Epoch 9/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0107 - accuracy: 0.9967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a9dc5a5e09a48ccb4abcff388958699",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo7ui7J1kXnd"
      },
      "source": [
        "## ArcFace based on Pytorch Implementation\n",
        "\n",
        "Essentially, in ArcFace, the logit is transform as follows $W^{\\intercal}x_i = ||W|| ||x_i|| cos(\\theta)$ where $\\theta$ is the angle between the weight $W$ and the feture $x_i$.\n",
        "Then basically the softmax-cors is replaced by:\n",
        "\n",
        "\n",
        "$$\\text{arc}(x_i) = \\frac{\\text{exp}(s(cos(\\theta_i) + m))}{\\text{exp}(s(cos(\\theta_i) + m)) + \\sum\\limits_{j=1;j\\neq i}^{m} \\text{exp}(s(cos(\\theta_j) + m))} $$,\n",
        "where $s$ is a scaling factor and $m$ is a margin penalty.\n",
        "\n",
        "Below follow the same example as aforementioned, but using the center loss.\n",
        "It's possible to observe from the t-SNE below that the representation for each one of the 10 classes is more \"visual\" compact (within class variability) compared with the cross-entropy example.\n",
        "\n",
        "> **This is what I understood from equation (3). It's tricky make a good descend on this.**:\n",
        "\n",
        "\n",
        "This implementation is based on:\n",
        "\n",
        "https://github.com/ronghuaiyang/arcface-pytorch/blob/master/models/metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd6su7QokXnd",
        "outputId": "c6fbe932-502e-41d3-fed3-20788e290b01",
        "colab": {
          "referenced_widgets": [
            "f99c54869e114ef1b9c09674e521fc1e"
          ]
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "\n",
        "# ARCFACE HYPER PARAMETERS\n",
        "S = 30.\n",
        "M = 0.2\n",
        "n_classes = 10\n",
        "\n",
        "\n",
        "class ArcFaceModel(tf.keras.Model):\n",
        "\n",
        "    def train_step(self, data):\n",
        "        X, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            logits = self((X,y), training=True)\n",
        "            loss = self.compiled_loss(\n",
        "                  y, logits, sample_weight=None, regularization_losses=self.losses)\n",
        "        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)            \n",
        "                   \n",
        "        self.compiled_metrics.update_state(y, logits, sample_weight=None)\n",
        "        return {m.name: m.result() for m in self.metrics}   \n",
        "\n",
        "\n",
        "class ArcFaceLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_classes=10, s=30, m=0.5):\n",
        "        super(ArcFaceLayer, self).__init__(name =\"arc_face_logits\")\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        super(ArcFaceLayer, self).build(input_shape[0])\n",
        "        shape = [input_shape[-1], self.n_classes]\n",
        "        \n",
        "        self.W = self.add_variable(\"W\", shape=shape)\n",
        "\n",
        "        self.cos_m = tf.identity(math.cos(self.m), name='cos_m')\n",
        "        self.sin_m = tf.identity(math.sin(self.m), name='sin_m')\n",
        "        self.th = tf.identity(math.cos(math.pi - self.m), name='th')\n",
        "        self.mm = tf.identity(math.sin(math.pi - self.m)*self.m)\n",
        "        \n",
        "        \n",
        "    \n",
        "    def call(self, X, y, training=None):\n",
        "        \n",
        "        # normalize feature\n",
        "        X = tf.nn.l2_normalize(X, axis=1)\n",
        "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
        "\n",
        "        # cos between X and W            \n",
        "        cos_yi = tf.matmul(X, W)\n",
        "\n",
        "        #sin_yi = tf.math.sqrt(1-cos_yi**2)\n",
        "        sin_yi = tf.clip_by_value(tf.math.sqrt(1-cos_yi**2), 0,1)\n",
        "\n",
        "        # cos(x+m) = cos(x)*cos(m) - sin(x)*sin(m)\n",
        "        cos_yi_m = cos_yi*self.cos_m - sin_yi*self.sin_m\n",
        "        \n",
        "        \n",
        "        cos_yi_m = tf.where(cos_yi > self.th, cos_yi_m, cos_yi - self.mm)\n",
        "        \n",
        "        \n",
        "        # Preparing the hot-output\n",
        "        one_hot = tf.one_hot(tf.cast(y, tf.int32), depth=self.n_classes,\n",
        "                          name='one_hot_mask')\n",
        "       \n",
        "\n",
        "        logits = (one_hot * cos_yi_m) + ((1.0 - one_hot) * cos_yi)\n",
        "    \n",
        "        #logits = tf.where(mask == 1., cos_yi_m, cos_yi)\n",
        "        logits = self.s*logits\n",
        "        \n",
        "        return logits        \n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_dataset = train_dataset.batch(64)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# PRE MODEL WITH CROSS ENTROPYn_classes = 10\n",
        "inputs = tf.keras.layers.Input([28, 28, 1], name=\"input\")\n",
        "labels = tf.keras.layers.Input([], name=\"label\")\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "# Creating PRE MODEL\n",
        "embeddings = tf.nn.l2_normalize(backbone(inputs, include_top=False), axis=1)\n",
        "logits_cross_entropy = tf.keras.layers.Dense(n_classes, name=\"hot\", activation=None)(embeddings)\n",
        "pre_model = tf.keras.Model(inputs=inputs, outputs=logits_cross_entropy)\n",
        "\n",
        "# Arcface model\n",
        "logits_arcface = ArcFaceLayer(s=S,m=M)(embeddings, labels)\n",
        "arcface_model = ArcFaceModel(inputs=(inputs,labels), outputs=logits_arcface)\n",
        "\n",
        "\n",
        "#print(pre_model.summary())\n",
        "\n",
        "pre_model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "pre_model.fit(train_dataset, epochs=1)\n",
        "\n",
        "\n",
        "\n",
        "# second do arcface\n",
        "#\n",
        "arcface_model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "arcface_model.fit(train_dataset, epochs=9)\n",
        "\n",
        "#arcface_model.fit([x_train, y_train],y_train, epochs=20)\n",
        "\n",
        "\n",
        "\n",
        "predict_model = tf.keras.Model(inputs=inputs, outputs=arcface_model.get_layer(\"embeddings\").output)\n",
        "embeddings = tf.nn.l2_normalize(predict_model.predict(x_test[0:1000]), axis=1)\n",
        "plot_scatter(embeddings, y_test[0:1000])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/idiap/user/tpereira/conda/envs/bob.nightlies/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2287: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 9s 8ms/step - loss: 0.4604 - accuracy: 0.9375\n",
            "Epoch 1/9\n",
            "938/938 [==============================] - 10s 9ms/step - loss: 0.7180 - accuracy: 0.9184\n",
            "Epoch 2/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.1919 - accuracy: 0.9743\n",
            "Epoch 3/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.1303 - accuracy: 0.9807\n",
            "Epoch 4/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.1065 - accuracy: 0.9843\n",
            "Epoch 5/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0977 - accuracy: 0.9850\n",
            "Epoch 6/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0666 - accuracy: 0.9881\n",
            "Epoch 7/9\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.0531 - accuracy: 0.9903\n",
            "Epoch 8/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0571 - accuracy: 0.9898\n",
            "Epoch 9/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0468 - accuracy: 0.9915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f99c54869e114ef1b9c09674e521fc1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtQHHZutkXnf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5wSMbpUkXng"
      },
      "source": [
        "## ArcFace + Sphere Face + CosFace\n",
        "\n",
        "$$L = -\\frac{1}{N} \\sum\\limits_{i=1}^{M} \\text{log} \\frac{\\text{exp}(s(cos(m_1\\theta_i + m_2) -m_3))}{\\text{exp}(s(cos(m_1\\theta_i + m_2) -m_3)) + \\sum\\limits_{j=1;j\\neq i}^{m} \\text{exp}(s(cos(\\theta_j)))} $$,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXLIaLf3kXng",
        "outputId": "04619ec9-488a-4779-f848-7338b0ef4610",
        "colab": {
          "referenced_widgets": [
            "7bd651f98f724cedbca02dbb55e24ce2"
          ]
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "\n",
        "# ARCFACE HYPER PARAMETERS\n",
        "S = 30.\n",
        "M1 = 1.\n",
        "M2 = 0.5\n",
        "M3 = 0\n",
        "ORIGINAL = False\n",
        "\n",
        "\n",
        "class ArcFaceLayer3Penalties(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_classes=10, s=30, m1=0.5, m2=0.5, m3=0.5):\n",
        "        super(ArcFaceLayer3Penalties, self).__init__(name =\"arc_face_logits\")\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m1 = m1\n",
        "        self.m2 = m2\n",
        "        self.m3 = m3        \n",
        "\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        super(ArcFaceLayer3Penalties, self).build(input_shape[0])\n",
        "        shape = [input_shape[-1], self.n_classes]\n",
        "        \n",
        "        self.W = self.add_variable(\"W\", shape=shape)\n",
        "\n",
        "        \n",
        "    \n",
        "    def call(self, X, y, training=None):\n",
        "        \n",
        "        # normalize feature\n",
        "        X = tf.nn.l2_normalize(X, axis=1)\n",
        "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
        "\n",
        "        # cos between X and W            \n",
        "        cos_yi = tf.matmul(X, W)\n",
        "\n",
        "        \n",
        "        # Getting the angle\n",
        "        theta = tf.math.acos(cos_yi)\n",
        "            \n",
        "        cos_yi_m = tf.math.cos(self.m1*theta+self.m2)-self.m3\n",
        "        \n",
        "        #logits = self.s*cos_theta_m\n",
        "        \n",
        "        # Preparing the hot-output\n",
        "        one_hot = tf.one_hot(tf.cast(y, tf.int32), depth=self.n_classes,\n",
        "                          name='one_hot_mask')\n",
        "       \n",
        "\n",
        "        logits = (one_hot * cos_yi_m) + ((1.0 - one_hot) * cos_yi)\n",
        "    \n",
        "        logits = self.s*logits\n",
        "        \n",
        "        return logits        \n",
        "\n",
        "        \n",
        "\n",
        "    \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_dataset = train_dataset.batch(64)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# PRE MODEL WITH CROSS ENTROPYn_classes = 10\n",
        "inputs = tf.keras.layers.Input([28, 28, 1], name=\"input\")\n",
        "labels = tf.keras.layers.Input([], name=\"label\")\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "# Creating PRE MODEL\n",
        "embeddings = tf.nn.l2_normalize(backbone(inputs, include_top=False), axis=1)\n",
        "logits_cross_entropy = tf.keras.layers.Dense(n_classes, name=\"hot\", activation=None)(embeddings)\n",
        "pre_model = tf.keras.Model(inputs=inputs, outputs=logits_cross_entropy)\n",
        "\n",
        "# Arcface model\n",
        "logits_arcface3p = ArcFaceLayer3Penalties(s=S,m1=M1, m2=M2, m3=M3)(embeddings, labels)\n",
        "arcface3p_model = ArcFaceModel(inputs=(inputs,labels), outputs=logits_arcface3p)\n",
        "\n",
        "\n",
        "#print(pre_model.summary())\n",
        "\n",
        "pre_model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "pre_model.fit(train_dataset, epochs=1)\n",
        "\n",
        "\n",
        "\n",
        "# second do arcface\n",
        "#\n",
        "arcface3p_model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "arcface3p_model.fit(train_dataset, epochs=9)\n",
        "\n",
        "#arcface_model.fit([x_train, y_train],y_train, epochs=20)\n",
        "\n",
        "\n",
        "\n",
        "predict_model = tf.keras.Model(inputs=inputs, outputs=arcface3p_model.get_layer(\"embeddings\").output)\n",
        "embeddings = tf.nn.l2_normalize(predict_model.predict(x_test[0:1000]), axis=1)\n",
        "plot_scatter(embeddings, y_test[0:1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/idiap/user/tpereira/conda/envs/bob.nightlies/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2287: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 8s 8ms/step - loss: 0.4604 - accuracy: 0.9375\n",
            "Epoch 1/9\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 1.5621 - accuracy: 0.8654\n",
            "Epoch 2/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.4412 - accuracy: 0.9612\n",
            "Epoch 3/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.3282 - accuracy: 0.9696\n",
            "Epoch 4/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2836 - accuracy: 0.9723\n",
            "Epoch 5/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2278 - accuracy: 0.9762\n",
            "Epoch 6/9\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.2005 - accuracy: 0.9791\n",
            "Epoch 7/9\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.1547 - accuracy: 0.9827\n",
            "Epoch 8/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.1492 - accuracy: 0.9826\n",
            "Epoch 9/9\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.1366 - accuracy: 0.9841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bd651f98f724cedbca02dbb55e24ce2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWW_JipZkXni",
        "outputId": "d0122534-92f4-4083-ef5f-c4a5a452e980"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "feats = torch.rand(5,5)\n",
        "W = torch.rand(5,4)\n",
        "cos_theta = torch.mm(feats, W)\n",
        "cos_theta_m = cos_theta + 100\n",
        "\n",
        "#labels = torch.Tensor([0,1,2,2,3]).int64()\n",
        "labels = torch.ones([5], dtype=torch.int64)\n",
        "labels[0] = 0; labels[1] = 1; labels[2] = 2; labels[3] = 2; labels[4] = 3;\n",
        "print(labels)\n",
        "print(\"\")\n",
        "#labels.type()\n",
        "\n",
        "\n",
        "index = torch.zeros_like(cos_theta)\n",
        "index.scatter_(1, labels.data.view(-1, 1), 1)\n",
        "index = index.byte()\n",
        "print(index)\n",
        "\n",
        "output = cos_theta\n",
        "print(output)\n",
        "#print(cos_theta_m)\n",
        "\n",
        "#output[index] = cos_theta_m[index]\n",
        "output = (index * cos_theta_m) + ((1.0 - index) * cos_theta)\n",
        "\n",
        "print(\"\")\n",
        "print(output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 2, 3])\n",
            "\n",
            "tensor([[1, 0, 0, 0],\n",
            "        [0, 1, 0, 0],\n",
            "        [0, 0, 1, 0],\n",
            "        [0, 0, 1, 0],\n",
            "        [0, 0, 0, 1]], dtype=torch.uint8)\n",
            "tensor([[1.9596, 1.2006, 1.5747, 1.0367],\n",
            "        [2.0889, 1.1229, 1.8871, 1.3343],\n",
            "        [1.7599, 1.1469, 2.1251, 1.4317],\n",
            "        [2.1005, 1.2008, 2.3277, 1.6029],\n",
            "        [0.6893, 0.4422, 0.8904, 0.5582]])\n",
            "\n",
            "tensor([[101.9596,   1.2006,   1.5747,   1.0367],\n",
            "        [  2.0889, 101.1229,   1.8871,   1.3343],\n",
            "        [  1.7599,   1.1469, 102.1251,   1.4317],\n",
            "        [  2.1005,   1.2008, 102.3277,   1.6029],\n",
            "        [  0.6893,   0.4422,   0.8904, 100.5582]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn0DBghlkXni"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJBfb1IJkXni"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}